[[2025-06-07]]

O deep learning sempre envolve as redes neurais artificiais que são inspiradas pelo funcionamento do cérebro humano e é utilizado para processar e interpretar grande volume de dados. 

As redes neurais artificial geralmente envolvem 3 camadas:
- Entradas
- Camadas ocultas
- Saída 

Quanto maior número de camadas ocultas, possui maior potência ou capacidade do próprio modelo em processar os dados mais complexos como vídeos e imagens.  Mas isso também significa que precisará de maior quantidade de dados e do maior poder de processamento.

___
Também temos a transferência de aprendizado onde não precisamos sempre treinar o modelo do zero a cada projeto, sendo possível pegar os modelos disponibilizados na internet que já vem treinados e que só precisa de ajustes finos.

Por exemplo, se você já treinou o modelo para reconhecer se a imagem contém carro, moto e assim por diante. Mas agora você precisa reconhecer se tem avião ou é carro, você também pode pegar um modelo que está na internet que já vem pré-treinado e realizar um fine tuning.

A outra vantagem é que os modelos pré-treinados também requer menor quantidade de dados do que treiná-lo do zero.

![[Pasted image 20250607185022.png]]

___

Os modelos antes de existir a nova arquitetura de transformador em ano 2017 eram:
- CNN (Convolutional Neural Network)
- RNN (Recurrent Neural Network)

CNN é bom em processar as imagens, sendo utilizado para fazer um reconhecimento de imagem e processamento.

RNN lida bem com dados sequenciais como textos, sendo excelente especialmente para PNL (Processamento de linguagem natural) e tradução automática. 

A nova arquitetura de transformadores utiliza o mecanismo de self-attention para compreender o relacionaemnto entre os elementos na sequência e lida muito melhor com a longa sequência de dados como texto enorme, algo que RNN tem muita dificuldade em fazê-lo. 
- Tem também capacidade de compreender as relações entre os dados de maneira global. E faz uma tarefa melhor em NLP do que RNN.

Nesse sentido, o transformador busca realizar as operações enquanto está processando os dados sequenciais, bem como ponderar a importância não somente na parte atual, porém em todas as partes.
- Ou seja, invés de focar sequencialmente cada palavra assim como RNN faz, o transformer consegue focar em diferentes partes da sequência ao mesmo tempo.
- É mais eficiente e mais paralelalizáveis do que os outros modelos, sendo bom para processar em GPU.

____
LLM são modelos de linguagem grande como o ChatGPT que interage com os modelos de GPT, e possuem grande poder de processamento de linguagem natural através de bilhões e trilhões parâmetros. 

Também fazem parte da área de IA generativa e Deep Learning, as subáreas do Machine learning, sendo baseada no modelo Transformer.

LLM são inicialmente treinados com grande volume de dados textuais, de maneira que aprendem a prever a sequência de palavras e preencher as lacunas a partir da padrão existente na idioma. 

Também pode ter um ajuste fine com um conjunto específico de dados para tarefas mais específicas como a tradução ou geração de código e assim por diante. Essa tarefa é feito de maneira supervisionada.

___

Porém, é importante enfatizar que os modelos de aprendizado de máquina como LLM são limitados a aquilo que está presente nos dados de treino, por mais que LLM tenha bastante conhecimento por ser treinado com vários tipos de texto.

Nesse sentido, pode ser que LLM não tenha nenhum conhecimento dos dados internos da própria empresa como documentos, notas fiscais, planilha e banco de dados. 

RAG (Retrieval Augmented Generation) é uma técnica que permite complementar um banco de dados externo (memória externa) a LLM para gerar os textos a partir dos dados internos da empresa.

Ou seja, RAG dispõe de um sistema de recuperação de informação para dar o contexto a LLM que precisa. Esse contexto pode incluir as informações com quais LLM não foi treinada.

A aplicação de RAG na empresa é interessante pois permite LLM consiga gerar texto ou analisar a partir dos dados internos da empresa.

GraphRAG é RAG, mas com os grafos para melhorar ainda mais a qualidade de resposta e contextualização. Atua de maneira mais eficiente ao utilizar os grafos como estrutura de informação mais organizada e estruturada.

Em RAG há duas partes, sendo que a primeira consiste em processar uma base de dados externa para recuperar as informações. A segunda parte vai utilizar o contexto gerado pelo processamento sobre essa base de dados para gerar resposta., além de integrar os dados que não estavam na base de dados 